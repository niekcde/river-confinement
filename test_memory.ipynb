{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/6256481/.conda/envs/RivAlg10/lib/python3.12/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import geopandas as gpd\n",
    "import psutil\n",
    "import os\n",
    "directory = '/scratch/6256481/'\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "os.chdir(directory + 'python/py_code')\n",
    "from dem import find_dem_bounds_FAB, find_dem_FAB\n",
    "from support import check_memory\n",
    "\n",
    "from osgeo import gdal\n",
    "from dem import get_raster_vrt\n",
    "vrt_file = directory + \"input_created/FAB_dem_vrt.vrt\"\n",
    "vrt_ds = gdal.Open(vrt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDemBounds = find_dem_bounds_FAB(directory, 'EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(np.sort(glob(directory + 'results/new_segments/vector/*'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import psutil\n",
    "import gc\n",
    "def list_variables():\n",
    "    \"\"\"List all variables in memory with their sizes.\"\"\"\n",
    "    variables = {name: sys.getsizeof(value) for name, value in globals().items()}\n",
    "    return sorted(variables.items(), key=lambda x: x[1], reverse=True)  # Sort by size\n",
    "\n",
    "\n",
    "def list_objects():\n",
    "    \"\"\"Get a list of all objects in memory.\"\"\"\n",
    "    return [str(type(obj)) for obj in gc.get_objects()]  # Limit to 20 items\n",
    "\n",
    "def get_object_ids():\n",
    "    \"\"\"Get a set of object IDs currently in memory.\"\"\"\n",
    "    return {id(obj): obj for obj in gc.get_objects()}\n",
    " # Show first 20 objects in memory\n",
    "\n",
    "def list_open_files():\n",
    "    \"\"\"List all currently open files by the Python process.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    return [f.path for f in process.open_files()]\n",
    "\n",
    "def find_largest_objects(objects, n=10):\n",
    "    \"\"\"Find the largest objects currently tracked by the garbage collector.\"\"\"\n",
    "    # objects = gc.get_objects()\n",
    "    sized_objects = [(sys.getsizeof(obj), type(obj), obj) for obj in objects]\n",
    "    sized_objects.sort(reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    print(f\"\\nTop {n} largest objects:\")\n",
    "    for size, obj_type, obj in sized_objects[:n]:\n",
    "        print(f\"{obj_type}: {size} bytes\")\n",
    "\n",
    "    return sized_objects[:n]  # Return for debugging if needed\n",
    "\n",
    "\n",
    "def find_and_remove_largest_objects(objects, n=10):\n",
    "    \"\"\"Find and attempt to remove the largest objects tracked by the garbage collector.\"\"\"\n",
    "    # objects = gc.get_objects()\n",
    "    sized_objects = [(sys.getsizeof(obj), type(obj), obj) for obj in objects]\n",
    "    sized_objects.sort(reverse=True, key=lambda x: x[0])  # Sort by size (largest first)\n",
    "\n",
    "    print(f\"\\nTop {n} largest objects before cleanup:\")\n",
    "    for size, obj_type, obj in sized_objects[:n]:\n",
    "        print(f\"{obj_type}: {size} bytes\")\n",
    "\n",
    "    # Attempt to remove these objects\n",
    "    for _, _, obj in sized_objects[:n]:\n",
    "        if isinstance(obj, (list, dict, set, tuple)):  # Handle common container types\n",
    "            obj.clear()\n",
    "        elif isinstance(obj, (str, bytes, bytearray)):\n",
    "            obj = \"\"  # Replace large strings with an empty string\n",
    "        else:\n",
    "            obj = None  # Try removing references\n",
    "\n",
    "    gc.collect()  # Force garbage collection\n",
    "\n",
    "    print(f\"Garbage collected. Remaining objects: {len(gc.get_objects())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274.85\n",
      "180817\n",
      "457.95\n",
      "\n",
      "463.36\n",
      "180884\n",
      "525.39\n",
      "\n",
      "530.8\n",
      "180951\n",
      "693.37\n",
      "\n",
      "698.8\n",
      "181018\n",
      "767.13\n",
      "\n",
      "772.77\n",
      "181085\n",
      "807.01\n",
      "\n",
      "812.4\n",
      "181152\n",
      "891.97\n",
      "\n",
      "897.33\n",
      "181256\n",
      "989.14\n",
      "\n",
      "994.94\n",
      "181323\n",
      "1083.51\n",
      "\n",
      "1089.04\n",
      "181397\n",
      "1175.46\n",
      "\n",
      "1181.03\n",
      "181464\n",
      "1270.37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = check_memory()\n",
    "gc.collect()\n",
    "\n",
    "for i, r in df.iloc[0:10].iterrows():\n",
    "    before_objects = get_object_ids()\n",
    "    print(check_memory())\n",
    "    dfR = df[df.index == i].copy()\n",
    "    dfR = dfR.to_crs(r['localCRS'])\n",
    "\n",
    "    R =  get_raster_vrt(vrt_ds, dfR,60000, r['localCRS'], 'EPSG:4326')\n",
    "\n",
    "\n",
    "    dfR = None\n",
    "    del dfR\n",
    "    gc.collect()\n",
    "    print(len(list_objects())) \n",
    "    after_objects = get_object_ids()\n",
    "\n",
    "    new_object_ids = set(after_objects.keys()) - set(before_objects.keys())\n",
    "    new_objects    = [after_objects[obj_id] for obj_id in new_object_ids]\n",
    "    # find_and_remove_largest_objects(new_objects)\n",
    "    print(check_memory())\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "221352\n",
    "\n",
    "221456\n",
    "\n",
    "221560\n",
    "\n",
    "221664\n",
    "\n",
    "221768\n",
    "\n",
    "221872\n",
    "\n",
    "221976\n",
    "\n",
    "222087\n",
    "\n",
    "222191\n",
    "\n",
    "222295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 largest objects:\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n"
     ]
    }
   ],
   "source": [
    "A1 = find_largest_objects(before_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 largest objects:\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n",
      "<class 'int'>: 32 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(32, int, 140621036950624),\n",
       " (32, int, 140621068337408),\n",
       " (32, int, 140621068338304),\n",
       " (32, int, 140621068353024),\n",
       " (32, int, 140621068345472),\n",
       " (32, int, 140621071908928),\n",
       " (32, int, 140621071917504),\n",
       " (32, int, 140621068031296),\n",
       " (32, int, 140621068538624),\n",
       " (32, int, 140621068536224)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = find_largest_objects(after_objects)\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 largest objects:\n",
      "<class 'dict'>: 10485848 bytes\n",
      "<class 'pandas.core.indexes.base.Index'>: 33136 bytes\n",
      "<class 'pandas.core.indexes.base.Index'>: 33136 bytes\n",
      "<class 'pandas.core.indexes.base.Index'>: 32304 bytes\n",
      "<class 'pandas.core.indexes.base.Index'>: 32304 bytes\n",
      "<class 'frozenset'>: 728 bytes\n",
      "<class 'collections.defaultdict'>: 232 bytes\n",
      "<class 'dict'>: 184 bytes\n",
      "<class 'dict'>: 184 bytes\n",
      "<class '_io.StringIO'>: 184 bytes\n",
      "<class 'function'>: 160 bytes\n",
      "<class 'xarray.core.dataarray.DataArray'>: 104 bytes\n",
      "<class 'xarray.core.variable.IndexVariable'>: 88 bytes\n",
      "<class 'list'>: 88 bytes\n",
      "<class 'list'>: 88 bytes\n"
     ]
    }
   ],
   "source": [
    "A = find_largest_objects(new_objects, n = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104,\n",
       " xarray.core.dataarray.DataArray,\n",
       " <xarray.DataArray (y: 4138, x: 4034)> Size: 67MB\n",
       " array([[-9999.  ,    30.54,    30.55, ..., -9999.  , -9999.  , -9999.  ],\n",
       "        [-9999.  ,    30.53,    30.54, ..., -9999.  , -9999.  , -9999.  ],\n",
       "        [-9999.  ,    30.51,    30.52, ...,    31.58,    31.62,    31.64],\n",
       "        ...,\n",
       "        [   17.75,    17.69,    18.11, ..., -9999.  , -9999.  , -9999.  ],\n",
       "        [   17.56,    17.57,    17.62, ..., -9999.  , -9999.  , -9999.  ],\n",
       "        [   17.35,    17.38,    17.56, ..., -9999.  , -9999.  , -9999.  ]],\n",
       "       dtype=float32)\n",
       " Coordinates:\n",
       "   * y        (y) float64 33kB 9.208e+04 9.205e+04 ... -3.545e+04 -3.548e+04\n",
       "   * x        (x) float64 32kB 1.886e+05 1.886e+05 ... 3.129e+05 3.129e+05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,\n",
       " list,\n",
       " [<weakref at 0x7fe4e479fbf0; dead>,\n",
       "  <weakref at 0x7fe4e44f8ae0; dead>,\n",
       "  <weakref at 0x7fe4e44f89f0; to 'Index' at 0x7fe4e4d6b1a0>])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 references to object.\n"
     ]
    }
   ],
   "source": [
    "refs = gc.get_referrers(A[11])\n",
    "print(f\"\\nFound {len(refs)} references to object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m refs:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Print some context about the references\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/RivAlg10/lib/python3.12/site-packages/shapely/geometry/base.py:165\u001b[0m, in \u001b[0;36mBaseGeometry.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m         wkt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (GEOSException, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# we never want a repr() to fail; that can be very confusing\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<shapely.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Exception in WKT writer>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    170\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ref in refs:\n",
    "    print(type(ref), ref)  # Print some context about the references\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/6256481/.ipython/profile_default/history.sqlite', '/home/6256481/.ipython/profile_default/history.sqlite', '/home/6256481/.conda/envs/RivAlg10/share/proj/proj.db']\n"
     ]
    }
   ],
   "source": [
    "# Find the dictionary in gc.get_objects()\n",
    "objects = gc.get_objects()\n",
    "for obj in objects:\n",
    "    if isinstance(obj, dict) and 'y' in obj and 'x' in obj:\n",
    "        print(\"Target dictionary found!\")\n",
    "        find_object_references(obj)\n",
    "        break  # Stop after finding the first match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/6256481/.conda/envs/RivAlg10/lib/python3.12/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5149.57\n",
      "5212.83\n",
      "\n",
      "5212.83\n",
      "5212.64\n",
      "\n",
      "5212.64\n",
      "5177.05\n",
      "\n",
      "5177.05\n",
      "5193.92\n",
      "\n",
      "5193.92\n",
      "5225.99\n",
      "\n",
      "5225.99\n",
      "5223.32\n",
      "\n",
      "5223.32\n",
      "5231.55\n",
      "\n",
      "5231.55\n",
      "5228.42\n",
      "\n",
      "5228.42\n",
      "5176.58\n",
      "\n",
      "5176.58\n",
      "5179.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i, r in df.iloc[0:10].iterrows():\n",
    "    \n",
    "    dfR = df[df.index == i].copy()\n",
    "    dfR = dfR.to_crs(r['localCRS'])\n",
    "    print(check_memory())\n",
    "    R = get_raster_vrt(vrt_ds, dfR,60000, r['localCRS'], 'EPSG:4326')\n",
    "    print(check_memory())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "\n",
    "# Load NetCDF file\n",
    "ds = xr.open_dataset(\"output_with_wkt.nc\")\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df = ds.to_dataframe().reset_index()\n",
    "\n",
    "# Convert WKT strings back to geometries\n",
    "df[\"geometry\"] = df[\"wkt_geometry\"].apply(loads)\n",
    "\n",
    "# Convert back to GeoDataFrame\n",
    "gdf_restored = gpd.GeoDataFrame(df, geometry=\"geometry\")\n",
    "\n",
    "print(gdf_restored.head())  # Verify restored geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
